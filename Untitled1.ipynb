{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f33ab90-cadf-4245-ab83-440cb3b9c54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# import main()\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import video\n",
    "import sys\n",
    "# import main()\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbfd18-9695-4aec-af02-7b4abacf8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFlag = True\n",
    "GREEN = (0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f876e4c-de94-4049-a380-24305f2de11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "    cv.polylines(vis, lines, 0, GREEN)\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv.circle(vis, (x1, y1), 1, GREEN, -1)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c711c33-06cb-4949-a4ec-e89856c309c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hsv(flow):\n",
    "    h, w = flow.shape[:2]\n",
    "    fx, fy = flow[:,:,0], flow[:,:,1]\n",
    "    angle = np.arctan2(fy, fx) + np.pi\n",
    "    v = np.sqrt(fx*fx+fy*fy)\n",
    "    hsv = np.zeros((h, w, 3), np.uint8)\n",
    "    hsv[...,0] = angle * (180/np.pi/2)\n",
    "    hsv[...,1] = 255\n",
    "    # hsv[...,2] = np.minimum(v*4, 255)\n",
    "    hsv[...,2] = cv.normalize(v, None, 0, 255, cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b72a09-db97-484e-835b-d3190e1b937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"./video/stoneturntable1.mp4\"\n",
    "pixel_x, pixel_y = 0, 0\n",
    "show_hsv, show_glitch = True, False\n",
    "# vid = input(\"video_path: \")\n",
    "# pixel_x, pixel_y = map(int, input('pixel location: ').split())\n",
    "# show_hsv = map(bool, input(\"Show HSV?: \"))\n",
    "# show_glitch = map(bool, input(\"Show glitch?: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1c0883-b31b-4d9e-a7b9-2376870bec0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cam \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mcreate_capture(\u001b[43mvid\u001b[49m)  \u001b[38;5;66;03m# cv.VideoCapture()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cam\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamera open failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vid' is not defined"
     ]
    }
   ],
   "source": [
    "cam = video.create_capture(vid)  # cv.VideoCapture()\n",
    "if not cam.isOpened():\n",
    "    print(\"Camera open failed!\")\n",
    "    sys.exit()\n",
    "# 캠의 속성값을 불러온다.\n",
    "w = round(cam.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cam.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cam.get(cv.CAP_PROP_FPS) # 카메라에 따라 값이 정상적, 비정상적\n",
    "# fourcc 값 받아오기, *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n",
    "fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
    "# 1프레임과 다음 프레임 사이의 간격 설정\n",
    "delay = round(1000/fps)\n",
    "\n",
    "# 웹캠으로 찰영한 영상을 저장하기\n",
    "# cv2.VideoWriter 객체 생성, 기존에 받아온 속성값 입력 \n",
    "flowout = cv.VideoWriter('./recorded/'+ vid.rstrip('.mp4') +'_flow.avi', fourcc, fps, (w, h))\n",
    "hsvout = cv.VideoWriter('./recorded/'+ vid.rstrip('.mp4') +'_hsv.avi', fourcc, fps, (w, h))\n",
    "\n",
    "# ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence\n",
    "_ret, prev = cam.read()\n",
    "# Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive\n",
    "prevgray = cv.cvtColor(prev, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "show_hsv = (show_hsv == 'True')\n",
    "show_glitch = (show_glitch == 'True')\n",
    "cur_glitch = prev.copy()\n",
    "magnitude_array = np.array([])\n",
    "loopcnt = 0\n",
    "pixelflow = np.zeros(w, h)\n",
    "print(np.shape(pixelflow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e88b1-5076-498d-a8ac-88e1461d6441",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    loopcnt += 1\n",
    "    # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video\n",
    "    _ret, frame = cam.read()\n",
    "    \n",
    "    # prints image size\n",
    "    # print(np.shape(frame))\n",
    "    \n",
    "    # Converts each frame to grayscale - we previously only converted the first frame to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Calculates dense optical flow by Farneback method\n",
    "    # https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\n",
    "\n",
    "    # prev, next: 이전 영상과 현재 영상\n",
    "    # flow: 계산된 옵티컬플로우\n",
    "    # pyr_scale: 피라미드 영상 만들 때 축소 비율\n",
    "    # levels: 피라미드 영상 개수\n",
    "    # winsize: 평균 윈도우 크기\n",
    "    # iterations: 각 피라미드 레벨에서 알고리즘 반복 횟수\n",
    "    # poly_n: 다항식 확장을 위한 이웃 픽셀 크기. 보통 5 or 7.\n",
    "    # poly_sigma: 가우시안 표준편차. 보통 poly_n = 5이면 1.1, poly_n = 7이면 1.5\n",
    "    # flags: 0, cv2.OPTFLOW_USE_INITIAL_FLOW, cv2.OPTFLOW_FARNEBACK_GAUSSIAN.\n",
    "    # flow = cv.calcOpticalFlowFarneback(prevgray, gray, None, pyr_scale = 0.5, \\\n",
    "    #                                    levels = 3, winsize = 15, iterations = 3, \\\n",
    "    #                                    poly_n = 5, poly_sigma = 1.2, flags = 0)\n",
    "    flow = cv.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    prevgray = gray\n",
    "    \n",
    "    ##### magnitude and angle #####\n",
    "\n",
    "    # Print cartesian value of magnitude and angle\n",
    "    magnitudeInCart = flow[..., 0]\n",
    "    angleInCart = flow[..., 1]\n",
    "    # if(printFlag):\n",
    "        # print(magnitudeInCart, angleInCart)\n",
    "\n",
    "    # Computes the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees = True)\n",
    "    polarFlow = np.stack([magnitude, angle], axis = 2)\n",
    "    \n",
    "    # Generating complex array for sound generation\n",
    "    \n",
    "    comp_polarFlow = np.vectorize(complex)(polarFlow[...,0], polarFlow[...,1])\n",
    "    flat_comp_polarFlow = np.ravel(comp_polarFlow, order='C')\n",
    "    ampphase = np.zeros_like(polarFlow)\n",
    "    ampphase[..., 0] = polarFlow[..., 0] + np.cos(np.deg2rad(polarFlow[...,1]))\n",
    "    ampphase[..., 1] = polarFlow[..., 0] + np.sin(np.deg2rad(polarFlow[...,1]))\n",
    "    comp_ampphase = np.vectorize(complex)(ampphase[...,0], ampphase[...,1])\n",
    "    flat_comp_ampphase = np.ravel(comp_ampphase, order='C')\n",
    "    # if(printFlag):\n",
    "        # print(\"magnitude: \", magnitude, \"angle: \", angle)\n",
    "        # print(\"shape: \", np.shape(magnitude), np.shape(angle))\n",
    "        \n",
    "    # prints out polarized magnitude and angle of input pixel position\n",
    "    pixel_magnitude = magnitude[pixel_x, pixel_y]\n",
    "    pixel_angle = angle[pixel_x, pixel_y]\n",
    "    if(printFlag):\n",
    "      print(pixel_magnitude, pixel_angle)\n",
    "    magnitude_array = np.append(magnitude_array, pixel_magnitude)\n",
    "\n",
    "    # prints out the average of polarized magnitude and angle\n",
    "    avg_magnitude = np.average(magnitude)\n",
    "    avg_angle = np.average(angle)\n",
    "    # if printFlag:\n",
    "        # print(avg_magnitude, avg_angle)\n",
    "        \n",
    "    ##### print #####  \n",
    "    if loopcnt == 100:\n",
    "        print(np.shape(flow))\n",
    "        print(flow)\n",
    "        print(np.shape(magnitude))\n",
    "        print(magnitude)\n",
    "        print(np.shape(angle))\n",
    "        print(angle)\n",
    "        print(np.shape(polarFlow))\n",
    "        print(polarFlow)\n",
    "        print(np.shape(comp_polarFlow))\n",
    "        print(comp_polarFlow)\n",
    "        print(np.shape(comp_ampphase))\n",
    "        print(comp_ampphase)\n",
    "    if loopcnt == 3600:\n",
    "    # flowout.write(draw_flow(gray, flow))\n",
    "    # hsvout.write(draw_hsv(flow))\n",
    "    # cv.imshow('flow', draw_flow(gray, flow))\n",
    "    # if show_hsv:\n",
    "    #     cv.imshow('flow HSV', draw_hsv(flow))\n",
    "    # if show_glitch:\n",
    "    #     cur_glitch = warp_flow(cur_glitch, flow)\n",
    "    #     cv.imshow('glitch', cur_glitch)\n",
    "    ch = cv.waitKey(1)\n",
    "    if ch == ord('q'):\n",
    "        break\n",
    "    if ch == ord('1'):\n",
    "        show_hsv = not show_hsv\n",
    "        print('HSV flow visualization is', ['off', 'on'][show_hsv])\n",
    "    if ch == ord('2'):\n",
    "        show_glitch = not show_glitch\n",
    "        if show_glitch:\n",
    "            cur_glitch = frame.copy()\n",
    "        print('glitch is', ['off', 'on'][show_glitch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fa036-3b0a-48b5-90aa-27541eaec72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "istfted = librosa.stft(flat_comp_ampphase)\n",
    "print(np.shape(istfted))\n",
    "print(istfted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8a5b5-ec3f-4c5d-891d-d289defefeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "flowout.release()\n",
    "hsvout.release()\n",
    "fs = loopcnt\n",
    "freq = magnitude_array\n",
    "x1 = np.sin(2*np.pi*freq*np.arange(freq)/fs)\n",
    "# ipd.Audio(x1, rate = fs)\n",
    "print(magnitude_array)\n",
    "print(loopcnt)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stt] *",
   "language": "python",
   "name": "conda-env-stt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
